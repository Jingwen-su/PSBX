---
title: "Caret"
author: "jingwen"
date: "12/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Dans cet article, nous utiliserons le package **caret** pour expliquer et pratiquer *le prétraitement et la segmentation des données*. 

Afin de mieux comprendre la fonction, cet article prendra [le données de carte de crédit](https://www.kaggle.com/sakshigoyal7/credit-card-customers) comme exemple pour la démonstration.

# Importez le package caret

```{r}
library(caret)
```
Si nous voulons effacer le répertoire de travail avant cela, utilisez:
```{r}
rm(list = ls())
```

# Prétraitement des données
## Traitement des valeurs manquantes 

1. supprimer:

```{r}
##Importer des données
dat1=read.table(file ="/Users/jingwensu/Desktop/BankChurners1.csv",encoding = "uft-8",sep=",",header = T,row.names = 1)
print(ncol(dat1))
##Afficher la taille de l'ensemble de données
nrow(dat1)
##Supprimer les valeurs manquantes
dat=na.omit(dat1)
nrow(dat)
```

2.La fonction **preProcess ()**
Il est intégrée à l'ensemble d'apprentissage. Il inclut:

1) Méthode médiane: method = "medianImpute"

```{r}
 #imputation_k = preProcess (datTrain, method = "medianImpute")
 #datTrain1 = prédire (imputation_k, datTrain)
 #datTest1 = prédire (imputation_k, datTest)
```

2) kNearest Neighbor Method: method = "knnImpute"; Cette méthode peut montrer que le résultat est composé de plusieurs décimales. Veuillez normaliser si nécessaire.


3. Traitement de la variable de variance 0
Lorsqu'un certain groupe de valeurs de données sont identiques ou sont toutes égales à 0, cela n'a aucun sens pour notre analyse, nous le supprimons donc.

```{r}
#dim (datTrain)
#(nzv = nearZeroVar (datTrain))
#datTrain = datTrain [, - nzv]
```

## Convertir le type de données
```{r}
dat$Gender =factor(dat$"Gender", levels = c("F","M"),labels =  c("Femme","homme"))
head(dat)
```

## Créer une partition de données

1. Divisez 80% des données dans l'ensemble d'apprentissage et 20% comme ensemble de test.

```{r}
trainIndex= createDataPartition(dat$Attrition_Flag, p= .8, list = FALSE, times = 1)
##Ensemble d'entraînement
datTrain= dat[trainIndex, ]
##Ensemble d'essai
datTest= dat[-trainIndex, ]
## La proportion de la variable dépendante à chaque niveau sur l'ensemble complet
table(dat$Attrition_Flag)/nrow(dat)
## La proportion de chaque niveau de la variable dépendante sur l'ensemble d'apprentissage
table(datTrain$Attrition_Flag)/nrow(datTrain)
## La proportion de la variable dépendante à chaque niveau de l'ensemble de test
table(datTest$Attrition_Flag)/nrow(datTest)
```

2. Validation croisée

```{r}
set.seed(1234)
index= createFolds(dat$Gender,k=3,list = FALSE,returnTrain = TRUE)

testIndex=which(index==1)
datTraincv=dat[-testIndex,]##ensemble d'entraînement
datTestcv=dat[testIndex,]##ensemble d'entraînement
```

3. À propos de la segmentation des séries chronologiques

```{r}
# data3= createTimeSlices(1:nrow(growdata),initialWindow=5,horizon=2,fixedWindow=TRUE)
```
Où 5 correspond à la fenêtre initiale, 2 signifie que l'ensemble de test correspond aux deux derniers chiffres de l'ensemble d'apprentissage, et la fenêtre fixe signifie que la largeur de l'ensemble d'apprentissage est la même. Si vous souhaitez partir du premier échantillon à chaque fois, définissez-le sur FALSE et par défaut sur TRUE.

## Traitement standardisé
Standardisez l'ensemble de test avec la moyenne et la variance de l'ensemble d'apprentissage.
```{r}
preProcValues= preProcess(datTrain,method = c("center","scale"))
trainTransformed= predict(preProcValues, datTrain)
testTransformed= predict(preProcValues,datTest)
```

## Sélection de variables
Méthode d'emballage rfe
```{r}
#### Pour choisir le nombre de variables
subsets= c(2,5,10,15,20,25,30,35,40)
#### Définir les paramètres de contrôle, les fonctions consistent à déterminer quel type de modèle est utilisé pour trier les variables indépendantes, voici une forêt aléatoire: selon la fonction objectif ou le score d'effet de prédiction, sélectionnez plusieurs fonctionnalités à chaque fois; la méthode consiste à déterminer la méthode d'échantillonnage à utiliser, Le cv utilisé ici est la validation croisée
ctrl = rfeControl(functions = rfFuncs,method = "cv")
x=trainTransformed[,-which(colnames(trainTransformed) %in%"Gender")]
y=trainTransformed[,"Gender"]
Profile=rfe(x,y, sizes=c(1:5),rfeControl = ctrl)
Profile$optVariables
## Formation et réglage du modèle
dat.train=trainTransformed[,c(Profile$optVariables,"Gender")]
dat.test=testTransformed[,c(Profile$optVariables,"Gender")]
## Forêt aléatoire
set.seed(1234)
gbmFitl=train(Gender ~., data = dat.train,method="rf")
# Utilisé pour former le modèle
importance=varImp(gbmFitl, scale=FALSE)
# Obtenez l'importance de chaque variable
plot(importance,xlab = "importance")
```


